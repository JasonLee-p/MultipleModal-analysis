{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvA9Z90OF_gh",
    "outputId": "2ac1f89f-b4db-4dfb-fb7c-6b7ec7e829d9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "omcCuV38uNBU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!cp ./drive/MyDrive/datasets/data.zip ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WiqPRvezueMG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "系统找不到指定的路径。\n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qsPHfzHnukSY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TxtR4WrOKudz"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29340\\1785355789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils as utils\n",
    "import seaborn as sns\n",
    "# 音频处理库\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(filename='train_ae.log', encoding='utf-8', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zlzxPxCK8XL"
   },
   "outputs": [],
   "source": [
    "def plot_spectogram(spectogram, ax, fig=None, title=\"Spectogram\"):\n",
    "    # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "    log_spectogram = librosa.amplitude_to_db(np.abs(spectogram), ref=np.max)\n",
    "    ax.set_title(title)\n",
    "    img = librosa.display.specshow(log_spectogram, ax=ax, x_axis='time', y_axis='log')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "\n",
    "def plot_wave(wave, ax):\n",
    "    ax.set_title('Wave')\n",
    "    ax.plot(wave, label='wave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWT_dK-cK-Nx"
   },
   "outputs": [],
   "source": [
    "def transform_wave_to_spectogram(wave, n_fft=2048, hop_length=256):\n",
    "    spectogram = librosa.stft(wave, n_fft=n_fft, hop_length=hop_length)\n",
    "    spectogram = np.abs(spectogram) # 此时数据还是比较极端，在对齐做log处理，再做均一化\n",
    "    spectogram = librosa.amplitude_to_db(spectogram, ref=np.max)\n",
    "    spectogram = spectogram.astype(np.float32)\n",
    "    spectogram = (spectogram - np.min(spectogram)) / (np.max(spectogram) - np.min(spectogram))\n",
    "    # normalize\n",
    "    return spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGyHTDuPLAHE"
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "configuration = {\n",
    "    \"datadirs\": \"./data\",\n",
    "    \"optim\": {\n",
    "        \"config\": {\n",
    "            \"lr\": 0.01,\n",
    "            \"weight_decay\": 0.0001\n",
    "        },\n",
    "        \"name\": \"Adam\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_hlQMfeLBEN"
   },
   "outputs": [],
   "source": [
    "# audio dataset\n",
    "class ChordDataSet(utils.data.Dataset):\n",
    "    def __init__(self, datadir, transform=transform_wave_to_spectogram):\n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        self.classes = []\n",
    "        self._load_data()\n",
    "    \n",
    "    def _load_data(self):\n",
    "        for root, dirs, files in os.walk(self.datadir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".wav\"):\n",
    "                    self.paths.append(os.path.join(root, file))\n",
    "                    label = root.split(\"\\\\\")[-1]\n",
    "                    self.labels.append(label)\n",
    "                    if label not in self.classes:\n",
    "                        self.classes.append(label)\n",
    "        self.num_class = len(self.classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        label = self.labels[index]\n",
    "        label = self.classes.index(label)\n",
    "        label = torch.zeros(self.num_class).scatter_(0, torch.tensor(label), 1)\n",
    "        wave, sr = librosa.load(path, sr=16000)\n",
    "        spectogram = torch.from_numpy(self.transform(wave)).unsqueeze(0)\n",
    "        return spectogram, label\n",
    "    def get_class(self, ind):\n",
    "        return self.classes[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_N3qvPyLB62"
   },
   "outputs": [],
   "source": [
    "class ContentEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.net_l = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.InstanceNorm2d(256),\n",
    "        )\n",
    "        self.net_r = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.Conv2d(128, 64, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.Conv2d(64, 1, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.InstanceNorm2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        res1 = self.net_l(x)\n",
    "        res2 = x + res1\n",
    "        res3 = self.net_r(res2)\n",
    "        # print(res1.shape, res2.shape, res3.shape)\n",
    "        return res3        \n",
    "\n",
    "class StyleEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.net_l = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.net_r = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        res1 = self.net_l(x)\n",
    "        res2 = x + res1\n",
    "        res3 = self.net_r(res2)\n",
    "        # print(res1.shape, res2.shape, res3.shape)\n",
    "        # 257 * 4\n",
    "        return res3        \n",
    "\n",
    "\n",
    "def adaIn(x, y):\n",
    "    std_x = torch.std(x, dim=(2, 3), keepdim=True)\n",
    "    mean_x = torch.mean(x, dim=(2, 3), keepdim=True)\n",
    "    std_y = torch.std(y, dim=(2, 3), keepdim=True)\n",
    "    mean_y = torch.mean(y, dim=(2, 3), keepdim=True)\n",
    "    return std_y * (x - mean_x) / std_x + mean_y\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ### 两个decoder层级，一个是style，一个是content\n",
    "        ### style decoder 中解构出来的与 content融合\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 64, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 128, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 1, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, content, style):\n",
    "        # resize content to 257 * 4\n",
    "        # resize style to 257 * 4\n",
    "        content = content.view(-1, 1, 257, 4)\n",
    "        style = style.view(-1, 1, 257, 4)\n",
    "        res = adaIn(content, style)\n",
    "        return self.net(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYznvK9xLDCp"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLlTSLU2LEoO"
   },
   "outputs": [],
   "source": [
    "# ae train\n",
    "\n",
    "\n",
    "ae_configuration = {\n",
    "    \"optim\": {\n",
    "        \"name\": \"Adam\",\n",
    "        \"config\": {\n",
    "            \"lr\": 0.001,\n",
    "        }\n",
    "    },\n",
    "    \"epoch\": 100,\n",
    "    \"batch_size\": 8\n",
    "}\n",
    "\n",
    "def train_ae(content_net, style_net, decoder_net, device = get_device(), alpha = 0.5, encoder_name=\"all\"):\n",
    "    \n",
    "    content_net.to(device)\n",
    "    style_net.to(device)\n",
    "    decoder_net.to(device)\n",
    "    print(\"加载数据集\")\n",
    "    dataset = ChordDataSet(\"./data\")\n",
    "    print(\"加载数据完成\")\n",
    "    dataloader = utils.data.DataLoader(dataset, batch_size=ae_configuration[\"batch_size\"], shuffle=True)\n",
    "    optim = getattr(torch.optim, ae_configuration[\"optim\"][\"name\"])\n",
    "    optim = optim(list(content_net.parameters()) + list(style_net.parameters()) + list(decoder_net.parameters()), **ae_configuration[\"optim\"][\"config\"])\n",
    "    criterion = nn.MSELoss()\n",
    "    print(\"开始训练\")\n",
    "    for epoch in range(ae_configuration[\"epoch\"]):\n",
    "        for i, (data, label) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            optim.zero_grad()\n",
    "            content = content_net(data)\n",
    "            style = style_net(data)\n",
    "            output = decoder_net(content, style)\n",
    "            loss = (1 - alpha) * torch.mean(content) + alpha * criterion(output, data)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            if i % 20 == 0:\n",
    "                print(f\"epoch: {epoch}, iter: {i}, loss: {loss.item()}\")\n",
    "        torch.save(content_net.state_dict(), f\"./model/content_net_{encoder_name}_{epoch}.pth\")\n",
    "        torch.save(style_net.state_dict(), f\"./model/style_net_{encoder_name}_{epoch}.pth\")\n",
    "        torch.save(decoder_net.state_dict(), f\"./model/decoder_net_{encoder_name}_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2J2W3MyXLMi-",
    "outputId": "2e0ac444-ec9a-4edf-f424-48c628145a62"
   },
   "outputs": [],
   "source": [
    "content_encoder = ContentEncoder()\n",
    "style_encoder = StyleEncoder()\n",
    "decoder = Decoder()\n",
    "\n",
    "# train_ae(content_encoder, style_encoder, decoder)\n",
    "\n",
    "content_encoder.load_state_dict(torch.load('./model/all_c_encoder.pth'))\n",
    "style_encoder.load_state_dict(torch.load('./model/all_s_encoder.pth'))\n",
    "decoder.load_state_dict(torch.load('./model/all_decoder.pth'))\n",
    "content_encoder.to(get_device())\n",
    "style_encoder.to(get_device())\n",
    "decoder.to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73jQJTpQFFPz"
   },
   "outputs": [],
   "source": [
    "def restart():\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zepDYxw0HLfM"
   },
   "outputs": [],
   "source": [
    "# restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYPu8BNsvEWV"
   },
   "outputs": [],
   "source": [
    "dataset = ChordDataSet('./data/V3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "568iwHqj4ArT",
    "outputId": "5b7ffd36-3fe2-4a47-9f77-fdc496a4de74"
   },
   "outputs": [],
   "source": [
    "content_encoder.eval()\n",
    "style_encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwWhZDkq7egZ"
   },
   "source": [
    "#### 测试一下 AE 的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWm6BI_x4B8o"
   },
   "outputs": [],
   "source": [
    "sample_x = dataset[100][0].to(get_device())\n",
    "content_feature = content_encoder(sample_x)\n",
    "style_feature = style_encoder(sample_x)\n",
    "decoder_ans = decoder(content_feature, style_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "8OPEo8u-4y1_",
    "outputId": "20baf56b-37e1-4d4e-ebcd-a88884bbe5ae"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(decoder_ans.detach().cpu()[0][0])\n",
    "# sns.heatmap(content_feature.detach().cpu()[0].view(257, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "-PsO5QRZ49YO",
    "outputId": "6ddec922-be80-4e00-f9e2-490524e1c7bc"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(sample_x.cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "XYspYZC36AnZ",
    "outputId": "5b2de8d8-c6af-4c3f-c2ba-786fa3dc702a"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(decoder_ans.detach().cpu()[0][0] - sample_x.cpu()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Clew6uGz6xZQ"
   },
   "source": [
    "* 可以发现encoder和decoder的效果还是非常不错的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgHrEjSK7kbW"
   },
   "source": [
    "### 如果交换一下顺序效果就会差很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8OHKpY760wK"
   },
   "outputs": [],
   "source": [
    "decoder_ans = decoder(content_feature, torch.rand_like(style_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "0BONa0dJ7xR8",
    "outputId": "46860621-1400-4774-9d44-ee8acd9937aa"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(decoder_ans.detach().cpu()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "tLXCLfIJ7zOi",
    "outputId": "2be97b37-2479-4524-8ab9-98efb20b7190"
   },
   "outputs": [],
   "source": [
    "decoder_ans = decoder(torch.rand_like(content_feature), style_feature)\n",
    "sns.heatmap(decoder_ans.detach().cpu()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSNCQFhv8SRm"
   },
   "source": [
    "!!!!!!!!!!!!! 真的真的真的出现了，\n",
    "真的提取出来了！！！！！\n",
    "太棒了！！！！\n",
    "开始训练分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zV9z9fZ_8pmR"
   },
   "source": [
    "同一个音频的音色特征是否相同呢??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "qdEVAI-N791E",
    "outputId": "c608bc2e-1415-4fd5-8455-4f2a0924ce28"
   },
   "outputs": [],
   "source": [
    "def get_label(label, dataset=ChordDataSet('./data/Error')):\n",
    "    index = torch.argmax(label)\n",
    "    return dataset.labels[index]\n",
    "get_label(dataset[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "NbgwlkCD8vau",
    "outputId": "147a324b-fa29-4445-9d10-1abf2132cd09"
   },
   "outputs": [],
   "source": [
    "sample_D_0_1 = style_encoder(dataset[10][0].to(get_device()))\n",
    "sample_D_0_2 = style_encoder(dataset[400][0].to(get_device()))\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 10))\n",
    "\n",
    "\n",
    "sns.heatmap(sample_D_0_1[0].detach().cpu().view(257, 4), ax=axes[0])\n",
    "sns.heatmap(sample_D_0_2[0].detach().cpu().view(257, 4), ax=axes[1])\n",
    "sns.heatmap(dataset[10][0][0].detach().cpu(), ax=axes[2])\n",
    "sns.heatmap(dataset[400][0][0].detach().cpu(), ax=axes[3])\n",
    "sns.heatmap((sample_D_0_1[0].detach().cpu() - sample_D_0_2[0].detach().cpu()).view(257, 4), ax=axes[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atiilUFM_RNX"
   },
   "source": [
    "可以发现，的的确确是提取出特征来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iliE_X0BlMq"
   },
   "outputs": [],
   "source": [
    "class ChordRecognizerWithFull(nn.Module):\n",
    "    def __init__(self, content_net, style_net, dataset = ChordDataSet('./data/Error'), device=get_device()):\n",
    "        super().__init__()\n",
    "        self.content_net = content_net.to(device)\n",
    "        self.content_net.eval()\n",
    "        self.style_net = style_net.to(device)\n",
    "        self.style_net.eval()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.InstanceNorm1d(num_features=1),\n",
    "            nn.Linear(257 * 4 * 2, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, dataset.num_class),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        content = self.content_net(x)\n",
    "        style = torch.flatten(self.style_net(x))\n",
    "        style = style.view(-1, 1028)\n",
    "        res = torch.cat([content, style], dim=1)\n",
    "        res = self.net(res)\n",
    "        return res\n",
    "\n",
    "class ChordRecognizerWithContent(nn.Module):\n",
    "    def __init__(self, content_net, dataset = ChordDataSet('./data/Error'), device=get_device()):\n",
    "        super().__init__()\n",
    "        self.content_net = content_net.to(device)\n",
    "        self.content_net.eval()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.InstanceNorm1d(num_features=1),\n",
    "            nn.Linear(257 * 4, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, dataset.num_class),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        content = self.content_net(x)\n",
    "        res = self.net(content)\n",
    "        return res\n",
    "\n",
    "class ChordRecognizerWithStyle(nn.Module):\n",
    "    def __init__(self, style_net, dataset = ChordDataSet('./data/Error'), device=get_device()):\n",
    "        super().__init__()\n",
    "        self.style_net = style_net.to(device)\n",
    "        self.style_net.eval()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.InstanceNorm1d(num_features=1),\n",
    "            nn.Linear(257 * 4, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, dataset.num_class),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        style = torch.flatten(self.style_net(x))\n",
    "        style = style.view(-1, 1028)\n",
    "        res = self.net(style)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-xhro5TB_gB"
   },
   "outputs": [],
   "source": [
    "from utils import load_chord_predictor\n",
    "\n",
    "content_predictor, style_predictor, all_predictor, dataset = load_chord_predictor()\n",
    "\n",
    "loss_record = {\n",
    "    \"cs_net\": [],\n",
    "    \"c_net\": [],\n",
    "    \"s_net\": [],\n",
    "    \"cs_acc\": [],\n",
    "    \"c_acc\": [],\n",
    "    \"s_acc\": [],\n",
    "}\n",
    "\n",
    "cls_configuration = {\n",
    "    \"optim\": {\n",
    "        \"cs_net\": {\n",
    "            \"name\": \"SGD\",\n",
    "            \"config\": {\n",
    "                \"lr\": 0.01,\n",
    "            }\n",
    "        },\n",
    "        \"c_net\": {\n",
    "            \"name\": \"SGD\",\n",
    "            \"config\": {\n",
    "                \"lr\": 0.01,\n",
    "            }\n",
    "        },\n",
    "        \"s_net\": {\n",
    "            \"name\": \"SGD\",\n",
    "            \"config\": {\n",
    "                \"lr\": 0.01,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"epoch\": 100,\n",
    "    \"batch_size\": 8,\n",
    "    # \"random_seed\": 42,\n",
    "    \"alpha\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdazQR9b_0Ca"
   },
   "outputs": [],
   "source": [
    "def train_cls(cs_net, c_net, s_net, configuration, record, device=get_device()):\n",
    "    cs_optim = getattr(torch.optim, configuration[\"optim\"][\"cs_net\"][\"name\"])(cs_net.parameters(), **configuration[\"optim\"][\"cs_net\"][\"config\"])\n",
    "    c_optim = getattr(torch.optim, configuration[\"optim\"][\"c_net\"][\"name\"])(c_net.parameters(), **configuration[\"optim\"][\"c_net\"][\"config\"])\n",
    "    s_optim = getattr(torch.optim, configuration[\"optim\"][\"s_net\"][\"name\"])(s_net.parameters(), **configuration[\"optim\"][\"s_net\"][\"config\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "\n",
    "    # set random seed\n",
    "    # torch.manual_seed(configuration[\"random_seed\"])\n",
    "    # torch.cuda.manual_seed(configuration[\"random_seed\"])\n",
    "    # np.random.seed(configuration[\"random_seed\"])\n",
    "\n",
    "    # split train and test\n",
    "    epoch = configuration[\"epoch\"]\n",
    "    batch_size = configuration[\"batch_size\"]\n",
    "    alpha = configuration[\"alpha\"]\n",
    "    dataset = ChordDataSet(\"./data/V3\")\n",
    "    ano_dataset = ChordDataSet(\"./data\")\n",
    "    dataset.classes = ano_dataset.classes\n",
    "    dataset.num_class = ano_dataset.num_class\n",
    "    train_data, test_data = utils.data.random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # to cuda\n",
    "    cs_net = cs_net.to(device)\n",
    "    c_net = c_net.to(device)\n",
    "    s_net = s_net.to(device)\n",
    "\n",
    "\n",
    "    # train\n",
    "    print(\"开始训练\")\n",
    "    for epoch in range(epoch):\n",
    "        for i, (data, label) in enumerate(train_dataloader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            cs_optim.zero_grad()\n",
    "            c_optim.zero_grad()\n",
    "            s_optim.zero_grad()\n",
    "            cs_output = cs_net(data)\n",
    "            c_output = c_net(data)\n",
    "            s_output = s_net(data)\n",
    "            cs_loss = criterion(cs_output, label)\n",
    "            c_loss = criterion(c_output, label)\n",
    "            s_loss = criterion(s_output, label)\n",
    "            cs_loss.backward()\n",
    "            c_loss.backward()\n",
    "            s_loss.backward()\n",
    "            cs_optim.step()\n",
    "            c_optim.step()\n",
    "            s_optim.step()\n",
    "            # print(f'cs: {cs_output.argmax(dim=1)},\\nc: {c_output.argmax(dim=1)}, \\ns: {s_output.argmax(dim=1)}, label: {label.argmax(dim=1)}')\n",
    "            if i % 10 == 0:\n",
    "                print(\"epoch: {}, batch: {}, cs_loss: {}, c_loss: {}, s_loss: {}\".format(epoch, i, cs_loss, c_loss, s_loss))\n",
    "                record[\"cs_net\"].append(cs_loss)\n",
    "                record[\"c_net\"].append(c_loss)\n",
    "                record[\"s_net\"].append(s_loss)\n",
    "            if i % 100 == 0 and i != 0:\n",
    "                # check acc\n",
    "                print(\"开始测试\")\n",
    "                with torch.no_grad():\n",
    "                    cs_acc = 0\n",
    "                    c_acc = 0\n",
    "                    s_acc = 0\n",
    "                    for i, (data, label) in enumerate(test_dataloader):\n",
    "                        data = data.to(device)\n",
    "                        label = label.to(device)\n",
    "                        cs_output = cs_net(data)\n",
    "                        c_output = c_net(data)\n",
    "                        s_output = s_net(data)\n",
    "                        cs_acc += (torch.argmax(cs_output, dim=1) == torch.argmax(label, dim=1)).sum()\n",
    "                        c_acc += (torch.argmax(c_output, dim=1) == torch.argmax(label, dim=1)).sum()\n",
    "                        s_acc += (torch.argmax(s_output, dim=1) == torch.argmax(label, dim=1)).sum()\n",
    "                    cs_acc = cs_acc / len(test_data)\n",
    "                    c_acc = c_acc / len(test_data)\n",
    "                    s_acc = s_acc / len(test_data)\n",
    "                    print(\"epoch: {}, batch: {}, cs_acc: {}, c_acc: {}, s_acc: {}\".format(epoch, i, cs_acc, c_acc, s_acc))\n",
    "                    record[\"cs_acc\"].append(cs_acc)\n",
    "                    record[\"c_acc\"].append(c_acc)\n",
    "                    record[\"s_acc\"].append(s_acc)\n",
    "        torch.save(cs_net.state_dict(), \"./model/all_cs_net_fine_{}.pth\".format(epoch))\n",
    "        torch.save(c_net.state_dict(), \"./model/all_c_net_fine_{}.pth\".format(epoch))\n",
    "        torch.save(s_net.state_dict(), \"./model/all_s_net_fine_{}.pth\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U2qOQRJ3AaGK",
    "outputId": "512253de-f3bc-4000-e1c3-7cc9c614bfd7"
   },
   "outputs": [],
   "source": [
    "train_cls(all_predictor, content_predictor, style_predictor, cls_configuration, loss_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLVlOUHjAnK1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
